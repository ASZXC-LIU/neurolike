这份总结将作为项目 **“NeuralLink Private Agent（代号）”** 的**最终需求规格说明书（SRS）**。它剥离了具体的编程语言，专注于**系统架构、数据流转、交互逻辑与核心价值**，旨在指导后续的工程落地。

------

### 🏛️ 项目愿景：NeuralLink Private Agent

构建一个**工业级架构、极低延迟、具备深度记忆与无限扩展能力**的私人本地 AI 伴生体。它不是一个简单的脚本工具，而是一个运行在双机环境下的**分布式智能操作系统**。

------

### 一、 物理部署架构：双机异构协同 (Dual-Machine Heterogeneous Architecture)

为了在有限的硬件资源下实现极致性能，采用**计算与交互彻底解耦**的策略。

#### 1. 算力节点 (Server Node)

- **硬件**：笔记本 (RTX 3060, 6GB VRAM)。
- **角色**：**无头 AI 推理引擎 (Headless AI Engine)**。
- **职责**：剥离所有业务逻辑，仅提供纯粹的张量计算能力。
- **服务矩阵 (HTTP/WebSocket)**：
  - **耳朵 (ASR)**：运行轻量级 `SenseVoiceSmall`，支持高并发、情感标签输出。
  - **大脑 (LLM)**：运行量化版 `Qwen2.5` 或 `Llama3` (3B/7B)或Gemini接口，专注于指令遵循与意图识别。
  - **嘴巴 (TTS)**：运行 `GPT-SoVITS`，提供高拟真、克隆级语音合成。
- **资源约束**：严格控制显存占用在 5.5GB 以内，预留 0.5GB 防止 OOM。

#### 2. 交互中枢 (Client Node)

- **硬件**：高性能主力台式机。
- **角色**：**智能体内核与编排器 (Agent Kernel & Orchestrator)**。
- **职责**：负责所有的 I/O 交互、状态管理、记忆检索、业务逻辑调度及插件执行。
- **形态**：Live2D 渲染形态。

------

### 二、 核心交互体验：流式与拟人 (Streaming & Anthropomorphism)

目标是打破“对讲机式”的生硬感，实现**类人级别的实时对话流**。

#### 1. 句级流式并发管线 (Sentence-Level Concurrent Pipeline)

- **机制**：放弃“全接收再处理”。
  - LLM 生成 Token 流 -> **语义/标点截断 (Semantic Chunking)**。
  - 截断后的句子块立即推入 TTS 队列 -> 合成音频流。
  - 音频流立即推入播放器队列 -> 扬声器发声。
- **效果**：实现首字音频延迟 (TTFA) < 1秒。

#### 2. 延迟掩盖与心跳填充 (Latency Masking)

- **机制**：在 VAD 检测用户说完话后，若 LLM 思考或工具调用耗时超过设定阈值（如 500ms），系统自动在播放队列首部插入预渲染的填充音（如“嗯…”、“让我想想…”）。
- **价值**：消除网络/计算延迟带来的空白焦虑，极大提升拟人感。

#### 3.基于情感的“动态发音”与“语气词感知”

目前的 TTS 只是把文本转语音，但人类生气和温柔时的语速、语调是完全不同的。

- **优化方案**：**SSML 动态标记注入**。
- **实现逻辑**：大脑根据 `thought` 推演出的情绪标签，自动在 `speak` 文本中注入 SSML 指令（如调整语速 $<1.2x>$ 或音高 $<+2st>$）。
- **副语言感知**：`SenseVoiceSmall` 识别出的用户叹气、笑声、犹豫（“呃...”、“那个...”）应作为独立字段传给 LLM。如果用户叹气，AI 的独白中应该触发“关心”逻辑。



#### 3. 感知层防御 (AEC & VAD)：

- **AEC (回声消除)**：硬件级/算法级抠除扬声器声音，防止 AI “自录自听”。
- **智能打断 (Barge-in)**：AI 发声时，若 VAD 检测到用户高置信度说话，AI 立即闭嘴切换至倾听态。

#### 4.交互层：多模态情感表达 (Live2D)：

- **机制**：在客户端展示 Live2D 模型，其表情、动作、眼神注视与 `Mood_Score`（情绪值）实时联动。
- **事例**：当 AI 生气时，Live2D 形象会皱眉、侧头，甚至在拒绝指令时直接闭眼不理用户。
- **优化：**
    - 如果 AI 当前处于“生气”或“极度关注”状态，应该调高 ASR 的灵敏度或者降低 VAD 的断句阈值，处于“待哄”状态的 AI 应该能灵敏地捕捉到，而不是因为音量太小而忽略。
    - 时间戳对齐 (Timestamping)。3060 传回音频块时，带上序列号或时间戳。Live2D 的动作序列应根据音频流的播放进度进行动态偏移调整，确保“对口型”的精准。
    - **基于振幅的口型驱动**。3060 传回的不仅是音频流，还应包含每 20ms 的**音频振幅数据 (Volume DB)**。Client 端 Live2D 引擎根据振幅动态调整模型口型开合度（`ParamMouthOpenY`），实现“音在嘴动”的真实感。

#### 5. 状态机驱动的感知 (State-Machine VAD)

- **机制**：使用严谨的**有限状态机 (FSM)** 管理麦克风。
  - `Idle` (空闲) -> `Listening` (VAD触发) -> `Processing` (处理中) -> `Speaking` (AI发声)。
- **智能打断 (Barge-in)**：在 `Speaking` 状态下，若 VAD 再次检测到高置信度人声，立即中断播放队列，强制状态机回滚至 `Listening`。

------



### 三、 大脑决策：双轨路由与自主意识

- **脊髓反射：语义路由 (Semantic Router)**：本地向量匹配 (< 5ms)，直接拦截简单指令（如“调大音量”），不经过 3060。
- **意图路由器 (Intent Router)**：LLM 接收复杂文本后先判定：是闲聊（走流式回复）还是指令（挂起回复，触发插件）。
- **内部独白 (Inner Monologue)**：大模型强制输出 `{thought, speak}` 结构。在 `thought` 中进行情绪推演和策略选择。**效率优化**：$thought$ 长度**可自定义限制**，防止 Token 溢出与延迟增加。

    - 在回复前，必须在 `thought` 字段中评估当前用户情绪和自身设定的“心情值”，自主推演出是否配合、是否傲娇或拒绝。系统仅播报 `speak` 字段。

    - **补充建议**：`thought` 字段虽然受限，但在连续对话中，AI 重复思考相同逻辑是很浪费的。

      **优化逻辑**：引入“情绪惯性”。如果连续三轮对话你的态度都没变，AI 应该缓存上一次的 `thought` 核心逻辑，直接生成 `speak`。
- **自主行动权 (System Tick)**：后台定时节拍广播，触发 AI 观察环境并主动发起交互。

    - **机制**：客户端中枢维护一个后台节拍器 (Cron Tick)。在特定时间或环境触发时，向总线广播 `Event_SystemTick` 并附带环境上下文（如时间、屏幕状态）。LLM 收到后可进行内部独白，并自主决定发起行动（如主动发声提醒休息）。

    - 引入 **“干扰容忍度 (Disturbance Tolerance)”** 参数，用户可以自己设置不同状态下的参数。

      **实现逻辑**：大脑在 `thought` 字段中不仅评估情绪，还要评估“紧迫性”。除非紧急情况（如笔记本低电量或检测到长时间高压工作或者用户在休闲），否则主动交互的频率应受限。增加一个**“一键闭嘴”**的硬物理开关（快捷键或托盘菜单），优先级高于一切 Tick 事件。，




### 四、 记忆系统：专业级嵌入式双轨架构 (Professional Embedded Dual-Track Memory)

本模块采用“计算归本地、存储归云端”的策略，确保数据在具备“遗忘曲线”拟人特性的同时，实现端到端的隐私保护。

#### 1. 短期记忆 (Working Memory)



 

- **存储介质**：内存 (RAM) + 磁盘 (SQLite WAL)。

- **短期记忆 (WAL 预写日志)**：所有对话在进入内存处理队列前，必须先同步落盘至本地 SQLite（标记为 `Pending`），确保崩溃重启后记忆不丢失。

- **逻辑**：维护最近 N 轮（如 10 轮）的对话上下文。

- **机制**：**滑动窗口 + 摘要坍缩**。当上下文即将溢出时，触发后台任务将旧对话压缩为摘要，保留核心信息。当对话溢出窗口时，触发后台任务将旧对话压缩为一段“语义摘要”并存入长期记忆，随后清空旧的原始 Token。

- **问题分析**：如果在你正聊得起劲时，后台突然启动“摘要坍缩”任务，由于 LLM 正在处理总结，可能会导致你的下一句回复出现明显的延迟抖动。

    - **优化建议**：**空闲触发机制**。

    - **实现逻辑**：坍缩任务不应只在“溢出时”触发，而应优先在 **Idle (空闲)** 状态下触发。只有当内存真的快爆了，才强制执行。

#### 2. **长期记忆 - 事实与规则 (Long-Term: Rules)**

- **存储介质**：嵌入式关系型数据库 (SQLite)。

- **内容与机制**：强类型约束存储用户画像、系统配置、插件状态，保证行为确定性。

- **本地主控**：主力机维护一份完整的事实库，用于毫秒级查询，确保 AI 行为的确定性。

  **加密快照**：定期将 SQLite 文件进行 AES 加密，打包上传至服务器备份。

#### 3. 长期记忆 (Long-Term Memory) - 语义与经验

- **存储介质**：**本地向量库 (Local Vector Index)** + **加密存储池 (Encrypted Data Pool)**。

- **内容**：历史对话的语义片段、非结构化的知识积累.

- **本地缓存**：常用事实与近期语义索引存储在 Client 端以保障速度。

  **远程同步**：全量数据同步至**远程服务器**（也可能为127.0.0.1），支持多端数据一致性。

- **机制**：**RAG (检索增强生成)**。

  - **写入流程**：对话 $\to$ 本地 Embedding 向量化 $\to$ 向量索引存入本地（仅存向量与 ID） $\to$ 对话原文进行 **AES 本地加密** $\to$ 发送至服务器存储。

    **读取流程 (RAG)**：新问题 $\to$ 本地向量匹配 $\to$ 召回 **Top-K** 条相关记录的 **ID** $\to$ 根据 ID 从远程服务器（或 127.0.0.1）请求加密块 $\to$ **本地解密原文** $\to$ 注入 Prompt。

  - **读取逻辑 (动态加权召回)**：系统在执行 Top-K 召回时，不再仅依赖向量相似度，而是采用**时效与情感双加权算法**计算最终检索得分：

$$Score_{final} = S_{vector} \cdot e^{-\lambda \Delta t} + \beta \cdot \text{Mood\_Score}$$

**逻辑冲突自修复**：当新老偏好冲突时，若 $Score_{final}$ 差距小于 15%，触发 `Inner Monologue` 确认逻辑；若差距过大，则由系统根据“置信度静默更新”逻辑自动覆盖旧事实。

- 
    - **时间衰减 (遗忘曲线)**：确保近期的、高时效性的记忆具有更高的被唤醒权重。
    -  **情绪增益 (性格映射)**：使带有强烈情绪标记（由 ASR 或内省引擎生成）的记忆能够打破时间限制，在特定语境下被优先唤醒。

    - **冲突自修复机制**：当检索结果中出现 $Score_{final}$ 接近但内容冲突的事实（如：新旧偏好矛盾）时，触发 `Inner Monologue` 的确认逻辑，实现记忆的动态更新与自修复。



-  “记忆自修复”的逻辑幻觉 (Self-healing Hallucination)
    当检索到冲突事实时，LLM 应该在 `thought` 中主动发起确认：“我记得你以前喜欢红色的，现在换口味了吗？”
-  
    - **问题分析**：当检索到冲突事实（红玫瑰 vs 白玫瑰）时，LLM 发起确认。
    - **潜在风险**：如果用户此时正在处理紧急任务，AI 的频繁确认会变成骚扰。
    - **优化建议**：增加**“置信度静默更新”**逻辑。
    - **方案**：若用户在回复中自然地使用了新事实（如“把这朵**白**玫瑰插起来”），系统应自动调高新事实的权重并静默覆盖，无需显式询问。











- **端到端加密**：数据传输至服务器前必须进行本地 AES 加密。服务器仅作为“加密后的冷数据桶”，不具备解密能力，也无法进行语义搜索。

    - **问题分析**：如果你重装了系统且没备份本地私钥，服务器上那几百 GB 的加密记忆就全部变成无法破解的垃圾了。

    -   **优化建议**：**助记词备份方案**。

        **实现逻辑**：在第一次设置加密时，强制生成类似加密货币钱包的“助记词”，由用户离线保存，作为找回记忆的唯一钥匙。或者在服务器/客户端保存备份







- - 

------

### 五、 扩展性架构：微内核与插件化 (Microkernel & Plugin System)

系统本体只负责调度，所有能力通过**插件**实现。

#### 1. 核心总线 (Event Bus)

- 采用 **发布/订阅 (Pub/Sub)** 模式解耦各模块。（**假设未来场景 1：你想增加一个“聊天记录面板 UI”** 你完全不需要改动上面任何一行的核心代码。你只需要新写一个 UI 模块，让它去**订阅** `Event_UserSpoke` 和 `Event_ActionCompleted`，只要广播站一响，UI 模块就把文本打印到屏幕上。

  **假设未来场景 2：你想接入一个“视觉模块”（截屏判断）** 你只需要写一个定时截屏的模块，识别到有趣的东西后，向总线**发布** `Event_VisualContextCaptured`。大脑层只要提前订阅了这个事件，就会自动对看到的画面做出反应。）

- 感知层发布事件 (`UserSpoke`)，大脑层发布意图 (`IntentDetected`)，执行层订阅并行动。

- 系统内的所有模块互不知晓，不发生直接调用，全部通过向总线**发布 (Publish)** 事件或**订阅 (Subscribe)** 事件来协作。

  - **第一阶段（感知）**：麦克风 VAD 监听到语音并转录后，不直接调用大模型，而是向总线广播 `Event_UserSpoke {text: "帮我打开网易云"}`。感知层随即切断联系，继续监听。
  - **第二阶段（大脑）**：大模型模块订阅了 `Event_UserSpoke`。收到广播后进行思考，识别出这是控制指令，随后向总线广播 `Event_IntentDetected {action: "PlayMusic", target: "网易云"}`。
  - **第三阶段（执行）**：独立的“音乐控制插件”订阅了意图事件。收到广播后在后台静默执行操作，完成后广播 `Event_ActionCompleted {status: "success"}`。
  - **第四阶段（反馈）**：TTS 模块收到完成广播，将其转化为语音播报给用户。

所谓“核心总线解耦”，就是**把流程控制权从“代码硬编码”交还给“事件流转”**。

#### 2. 插件生态 (Plugin Ecosystem)

- 通过 **Function Calling (函数调用)** 协议动态挂载能力。
- **规划插件群**：
  - **基础对话**：闲聊、情感陪伴。
  - **系统控制**：音量调节、App 启动、关机。
  - **文件操作**：本地文件读写、整理（替代 Opencode 部分功能）。
  - **通讯自动化**：IM 消息读取与回复。
  - **游戏宏控制**：Minecraft 指令注入、RCON 协议封装。

------



### 六、 执行层：Function Calling 与拟人化操作

- **能力插件化**：通过函数调用协议挂载文件操作、系统控制、通讯工具自动化。
- **执行层：拟人化输入干扰 (Input Mimicry)**：
  - **机制**：当 AI 接管键盘/鼠标操作时，模拟人类的非均匀输入速度与微小延迟。
  - **事例**：当 AI 帮你写代码或回复消息时，瞬间粘贴
  - 



### 七、 非功能性需求 (NFR)

1. **高效性 (Efficiency)**：
   - 通讯协议采用 **WebSocket** 或全双工流，拒绝 HTTP 轮询。
   - 使用嵌入式数据库，消除网络 I/O 开销。
2. **高质量 (Quality)**：
   - 代码结构需遵循 **Clean Architecture**（整洁架构），分层清晰（Domain, Application, Infrastructure）。
   - 具备健壮的错误处理与重连机制（当 3060 掉线时，客户端应优雅降级提示）。

3. **全系统参数化**：所有设定（灵敏度、阈值、模型路径等）均支持外部配置，拒绝写死。所有参数（IP、阈值、模型参数、内心独白长度限制）支持外部配置文件读取，预留 GUI 设置界面接口。
4. **优雅降级**：服务器或 3060 掉线时，Client 播放预设提示并尝试自动重连。
5. **灵魂数据集沉淀**：交互数据自动转为标准微调格式 (JSONL)，为未来 3060 本地炼制专属模型储备语料。

- **机制**：在事件总线末端挂载数据探针，静默收集带情绪标签的高质量对话，自动格式化为大模型指令微调 (Fine-tuning) 语料，为未来本地炼制真正专属的性格模型储备“药材”。



6.**沙箱白名单**：明确那些app允许ai接管，那些app允许只允许asr监听而不允许虚拟键鼠注入（防止反外挂）

7.3. 局域网发现与稳定性 (Networking)

- **问题分析**：双机架构依赖网络稳定性。
- - **潜在漏洞**：手动输入 IP 地址极其不便，且局域网波动会导致 WebSocket 频繁断连。
- - **补充需求**：增加 **“mDNS 服务发现”** 与 **“零配置组网”**。
    - **方案**：Client 自动发现局域网内的 Server 节点。增加“静默重连”机制。



### 八 开发者工具：内心独白调试器 (Monologue Debugger)

为了让你作为开发者能快速知道 AI 为什么“突然生气”，你需要一个黑匣子。

- **优化方案**：**实时日志面板**。
- **实现逻辑**：UI 界面预留一个隐藏开关，开启后能实时滚动显示 `thought` 字段的内容。
- **价值**：当你哄不好她时，可以偷偷看一眼她的“真实想法”，这对于你调试性格和情绪权重至关重要。















------







# 实现路线



- - ### 🛠️ NeuralLink 终极技术选型清单 (Tech Stack Blueprint)

    #### 一、 算力节点 (Server Node - RTX 3060 笔记本)

    **定位**：纯粹的无头张量计算黑盒，提供“耳、脑、嘴”的推理能力。

    - **核心语言**：**Python** (生态唯一解，无缝对接所有主流大模型库)。
    - **网关与通讯层**：**FastAPI** + **WebSocket**。
      - *职责*：FastAPI 作为 3060 节点唯一的出入口（网关）。它通过全双工 WebSocket 接收 Client 传来的二进制音频流和 JSON 指令，并异步返回推理结果。
    - **模型矩阵**：
      - **ASR (听觉)**：`SenseVoiceSmall` (极速语音转文本与情感提取)。
      - **LLM (大脑)**：`Qwen2.5` / `Llama3` (建议采用 4-bit 量化运行于 vLLM 或原生 Transformers)。
      - **TTS (发声)**：`GPT-SoVITS` (高拟真情感语音克隆)。

    #### 二、 交互中枢 (Client Node - 高性能主力机)

    **定位**：系统大脑皮层，负责 UI 渲染、记忆调度、硬件 I/O 及系统级操作接管。

    - **运行时环境**：**Node.js** + **Electron**  。
      - *职责*：利用 Electron 将 Web 技术打包成常驻后台、拥有系统最高权限的桌面级应用，支持托盘隐藏与全局快捷键（用于实现“一键物理熔断”）。
    - **前端表现层**：**Vue 3** + **TypeScript**。
      - *职责*：渲染悬浮面板、开发者日志工具（内心独白调试器）。强类型 (TS) 确保逻辑严密。
    - **多模态表现**：**Live2D WebGL SDK**。
      - *职责*：在 Vue 3 的 Canvas 中渲染 Live2D 模型，基于 WebSocket 传回的参数动态口型同步 (Lip-Sync) 与情感联动。
    - **系统级执行层 (Input Mimicry)**：**nut.js** 或 **robotjs**。
      - *职责*：Node.js 生态下的底层自动化库，用于实现带有随机延迟的“拟人化键盘/鼠标注入”，规避反作弊检测。

    #### 三、 架构解耦与通讯系统 (Architecture & Bus)

    **定位**：让各个模块像积木一样松耦合运作。

    - **双机外部桥梁**：**WebSocket** (标准 RFC 6455 协议)。
      - *职责*：跨设备高频通讯，拒绝 HTTP 轮询。
    - **进程内微内核总线 (Event Bus)**：**mitt**。
      - *职责*：运行在 Client 端的极简 TypeScript 事件总线。负责彻底解耦感知层、大脑层和执行层，实现即插即用的插件化生态。

    #### 四、 记忆与存储层 (Memory & RAG)

    **定位**：实现过目不忘、遗忘曲线与端到端隐私保护。

    - **短期记忆与规则库**：**SQLite** (配合 Node.js 的 `better-sqlite3` 库)。
      - *职责*：纯本地轻量级文件数据库，开启 WAL 模式，毫秒级读写事实库与 Pending 日志。
    - **语义经验向量库**：**ChromaDB** 或 **Qdrant**。
      - *职责*：部署在本地，负责将对话转化为向量存储，并支持基于时间与情绪权重的 Top-K 极速召回。
    - **加密与云同步**：
      - *加密算法*：Node.js 原生 `crypto` 模块 (AES-256-GCM 加密，助记词派生密钥)。
      - *云端冷存储*：任何支持 WebDAV 或 S3 协议的云盘/私有服务器（仅存放加密后的乱码分块）。